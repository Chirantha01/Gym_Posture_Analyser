{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path = r'movenet.tflite')\n",
    "interpreter.allocate_tensors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flipping Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipped and saved: 0_960x540.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 0_960x540.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 2potEB8qNMABrHqjfWIpOOvbyAbsNmbLb7_SAM9jEQE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 362-1.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 524.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: 6181ae52a3e0153fba71466fc28cb1fc595b4647_720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Barbell-Back-Squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Blog-Image-7-STANDING-AB-EXERCISES-THAT-WILL-STRENGTHEN-YOUR-CORE.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: f2-barbell-back-squat.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720 (1).jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: hq720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: man-1203899_1280.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181414.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181458.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181607.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181644.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 181720.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182206.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182443.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182809.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 182942.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183554.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183631.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183709.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Screenshot 2024-08-18 183735.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: Squat.StartPosition.GastownPhysioPilates.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n",
      "Flipped and saved: standing-position.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg_flipped.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def flip_images(input_dir, output_dir):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Loop through all the files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        # Construct the full file path\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(img_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            # Open the image\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Flip the image horizontally\n",
    "            flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            # Save the flipped image to the output directory\n",
    "            flipped_img.save(os.path.join(output_dir, filename+'_flipped.jpg'))\n",
    "            print(f\"Flipped and saved: {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "input_directory = r'C:\\Users\\2001l\\OneDrive\\Desktop\\squat\\upPosition'\n",
    "output_directory = r'C:\\Users\\2001l\\OneDrive\\Desktop\\squat\\upPosition'\n",
    "\n",
    "flip_images(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe of landmarks of the training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_from_standing_images(input_dir,X,Y):\n",
    "    for file in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(img_path) and file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img = Image.open(img_path)\n",
    "            img = tf.image.resize_with_pad(np.expand_dims(img,axis=0), 192, 192)\n",
    "            input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "            # Setup input and output\n",
    "            input_details = interpreter.get_input_details()\n",
    "            output_details = interpreter.get_output_details()\n",
    "\n",
    "            #make predictions\n",
    "            interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "            interpreter.invoke()\n",
    "            keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "            landmarks = keypoints_with_scores\n",
    "\n",
    "            X.append(landmarks)\n",
    "            Y.append(0)\n",
    "    return X,Y\n",
    "\n",
    "def landmarks_from_squating_images(input_dir,X,Y):\n",
    "    for file in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(img_path) and file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img = Image.open(img_path)\n",
    "            img = tf.image.resize_with_pad(np.expand_dims(img,axis=0), 192, 192)\n",
    "            input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "            # Setup input and output\n",
    "            input_details = interpreter.get_input_details()\n",
    "            output_details = interpreter.get_output_details()\n",
    "\n",
    "            #make predictions\n",
    "            interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "            interpreter.invoke()\n",
    "            keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "            landmarks = keypoints_with_scores\n",
    "\n",
    "            X.append(landmarks)\n",
    "            Y.append(1)\n",
    "    return X,Y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = landmarks_from_standing_images(r'upPosition',[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = landmarks_from_squating_images(r'downPosition',X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [1_x, 2_x, 3_x, 4_x, 5_x, 6_x, 7_x, 8_x, 9_x, 10_x, 11_x, 12_x, 13_x, 14_x, 15_x, 16_x, 17_x, 1_y, 2_y, 3_y, 4_y, 5_y, 6_y, 7_y, 8_y, 9_y, 10_y, 11_y, 12_y, 13_y, 14_y, 15_y, 16_y, 17_y, Y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate column names\n",
    "columns = [f\"{i}_x\" for i in range(1, 18)] + [f\"{i}_y\" for i in range(1, 18)] + ['Y']\n",
    "\n",
    "# Create an empty DataFrame with these columns\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2001l\\AppData\\Local\\Temp\\ipykernel_25692\\1965758734.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "y = 0\n",
    "for entry in X:\n",
    "    new_row = {col: None for col in columns}\n",
    "    x = 0\n",
    "    for x in range(1,18):\n",
    "        xName = str(x) + '_x'\n",
    "        yName = str(x) + '_y'\n",
    "        new_row[xName] = entry[0][0][x-1][0]\n",
    "        new_row[yName] = entry[0][0][x-1][1]\n",
    "        x = x+1\n",
    "    new_row['Y'] = Y[y]\n",
    "    y = y+1\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>10_x</th>\n",
       "      <th>...</th>\n",
       "      <th>9_y</th>\n",
       "      <th>10_y</th>\n",
       "      <th>11_y</th>\n",
       "      <th>12_y</th>\n",
       "      <th>13_y</th>\n",
       "      <th>14_y</th>\n",
       "      <th>15_y</th>\n",
       "      <th>16_y</th>\n",
       "      <th>17_y</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.327286</td>\n",
       "      <td>0.328188</td>\n",
       "      <td>0.335584</td>\n",
       "      <td>0.337321</td>\n",
       "      <td>0.376591</td>\n",
       "      <td>0.380630</td>\n",
       "      <td>0.395435</td>\n",
       "      <td>0.405161</td>\n",
       "      <td>0.371132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455058</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>0.452833</td>\n",
       "      <td>0.538660</td>\n",
       "      <td>0.492199</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>0.490987</td>\n",
       "      <td>0.564235</td>\n",
       "      <td>0.489883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337427</td>\n",
       "      <td>0.330524</td>\n",
       "      <td>0.334669</td>\n",
       "      <td>0.338237</td>\n",
       "      <td>0.339605</td>\n",
       "      <td>0.375162</td>\n",
       "      <td>0.382447</td>\n",
       "      <td>0.390089</td>\n",
       "      <td>0.408159</td>\n",
       "      <td>0.346712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430101</td>\n",
       "      <td>0.523434</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.505220</td>\n",
       "      <td>0.463085</td>\n",
       "      <td>0.507366</td>\n",
       "      <td>0.448752</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.434354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248382</td>\n",
       "      <td>0.234584</td>\n",
       "      <td>0.236951</td>\n",
       "      <td>0.245007</td>\n",
       "      <td>0.244894</td>\n",
       "      <td>0.292224</td>\n",
       "      <td>0.277356</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>0.338310</td>\n",
       "      <td>0.382827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713014</td>\n",
       "      <td>0.429093</td>\n",
       "      <td>0.720514</td>\n",
       "      <td>0.516982</td>\n",
       "      <td>0.610946</td>\n",
       "      <td>0.498965</td>\n",
       "      <td>0.643391</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.678543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.240113</td>\n",
       "      <td>0.242199</td>\n",
       "      <td>0.246664</td>\n",
       "      <td>0.248041</td>\n",
       "      <td>0.277887</td>\n",
       "      <td>0.293914</td>\n",
       "      <td>0.341917</td>\n",
       "      <td>0.363804</td>\n",
       "      <td>0.387278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570867</td>\n",
       "      <td>0.278646</td>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.385382</td>\n",
       "      <td>0.474913</td>\n",
       "      <td>0.346625</td>\n",
       "      <td>0.487613</td>\n",
       "      <td>0.319134</td>\n",
       "      <td>0.507263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.241581</td>\n",
       "      <td>0.232052</td>\n",
       "      <td>0.231702</td>\n",
       "      <td>0.251969</td>\n",
       "      <td>0.244944</td>\n",
       "      <td>0.315338</td>\n",
       "      <td>0.316320</td>\n",
       "      <td>0.416093</td>\n",
       "      <td>0.418072</td>\n",
       "      <td>0.356919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445377</td>\n",
       "      <td>0.497518</td>\n",
       "      <td>0.468692</td>\n",
       "      <td>0.557133</td>\n",
       "      <td>0.482137</td>\n",
       "      <td>0.591745</td>\n",
       "      <td>0.482272</td>\n",
       "      <td>0.614701</td>\n",
       "      <td>0.470514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.269335</td>\n",
       "      <td>0.255440</td>\n",
       "      <td>0.262633</td>\n",
       "      <td>0.248578</td>\n",
       "      <td>0.264382</td>\n",
       "      <td>0.315988</td>\n",
       "      <td>0.331319</td>\n",
       "      <td>0.370942</td>\n",
       "      <td>0.472705</td>\n",
       "      <td>0.351692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424774</td>\n",
       "      <td>0.252384</td>\n",
       "      <td>0.563788</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>0.268853</td>\n",
       "      <td>0.527715</td>\n",
       "      <td>0.553091</td>\n",
       "      <td>0.381434</td>\n",
       "      <td>0.422276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.152496</td>\n",
       "      <td>0.131350</td>\n",
       "      <td>0.130717</td>\n",
       "      <td>0.147583</td>\n",
       "      <td>0.143705</td>\n",
       "      <td>0.248949</td>\n",
       "      <td>0.246971</td>\n",
       "      <td>0.266599</td>\n",
       "      <td>0.254043</td>\n",
       "      <td>0.241453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304535</td>\n",
       "      <td>0.161116</td>\n",
       "      <td>0.155328</td>\n",
       "      <td>0.733582</td>\n",
       "      <td>0.631184</td>\n",
       "      <td>0.520522</td>\n",
       "      <td>0.423227</td>\n",
       "      <td>0.661199</td>\n",
       "      <td>0.525378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.157098</td>\n",
       "      <td>0.132782</td>\n",
       "      <td>0.134116</td>\n",
       "      <td>0.142868</td>\n",
       "      <td>0.145697</td>\n",
       "      <td>0.240384</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>0.251068</td>\n",
       "      <td>0.265584</td>\n",
       "      <td>0.243522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660548</td>\n",
       "      <td>0.841031</td>\n",
       "      <td>0.831572</td>\n",
       "      <td>0.380024</td>\n",
       "      <td>0.262156</td>\n",
       "      <td>0.575911</td>\n",
       "      <td>0.483287</td>\n",
       "      <td>0.470470</td>\n",
       "      <td>0.330142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.291138</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.280294</td>\n",
       "      <td>0.301488</td>\n",
       "      <td>0.296908</td>\n",
       "      <td>0.372551</td>\n",
       "      <td>0.364195</td>\n",
       "      <td>0.506963</td>\n",
       "      <td>0.483484</td>\n",
       "      <td>0.417078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579118</td>\n",
       "      <td>0.587216</td>\n",
       "      <td>0.574139</td>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.651935</td>\n",
       "      <td>0.581281</td>\n",
       "      <td>0.571586</td>\n",
       "      <td>0.655428</td>\n",
       "      <td>0.641182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.287423</td>\n",
       "      <td>0.276282</td>\n",
       "      <td>0.279109</td>\n",
       "      <td>0.294811</td>\n",
       "      <td>0.299027</td>\n",
       "      <td>0.369762</td>\n",
       "      <td>0.377475</td>\n",
       "      <td>0.491012</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.388003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417008</td>\n",
       "      <td>0.412433</td>\n",
       "      <td>0.400359</td>\n",
       "      <td>0.338844</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.428291</td>\n",
       "      <td>0.424024</td>\n",
       "      <td>0.353666</td>\n",
       "      <td>0.351520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1_x       2_x       3_x       4_x       5_x       6_x       7_x  \\\n",
       "0   0.332451  0.327286  0.328188  0.335584  0.337321  0.376591  0.380630   \n",
       "1   0.337427  0.330524  0.334669  0.338237  0.339605  0.375162  0.382447   \n",
       "2   0.248382  0.234584  0.236951  0.245007  0.244894  0.292224  0.277356   \n",
       "3   0.252336  0.240113  0.242199  0.246664  0.248041  0.277887  0.293914   \n",
       "4   0.241581  0.232052  0.231702  0.251969  0.244944  0.315338  0.316320   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "91  0.269335  0.255440  0.262633  0.248578  0.264382  0.315988  0.331319   \n",
       "92  0.152496  0.131350  0.130717  0.147583  0.143705  0.248949  0.246971   \n",
       "93  0.157098  0.132782  0.134116  0.142868  0.145697  0.240384  0.252563   \n",
       "94  0.291138  0.281100  0.280294  0.301488  0.296908  0.372551  0.364195   \n",
       "95  0.287423  0.276282  0.279109  0.294811  0.299027  0.369762  0.377475   \n",
       "\n",
       "         8_x       9_x      10_x  ...       9_y      10_y      11_y      12_y  \\\n",
       "0   0.395435  0.405161  0.371132  ...  0.455058  0.564492  0.452833  0.538660   \n",
       "1   0.390089  0.408159  0.346712  ...  0.430101  0.523434  0.440300  0.505220   \n",
       "2   0.367411  0.338310  0.382827  ...  0.713014  0.429093  0.720514  0.516982   \n",
       "3   0.341917  0.363804  0.387278  ...  0.570867  0.278646  0.568406  0.385382   \n",
       "4   0.416093  0.418072  0.356919  ...  0.445377  0.497518  0.468692  0.557133   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "91  0.370942  0.472705  0.351692  ...  0.424774  0.252384  0.563788  0.183186   \n",
       "92  0.266599  0.254043  0.241453  ...  0.304535  0.161116  0.155328  0.733582   \n",
       "93  0.251068  0.265584  0.243522  ...  0.660548  0.841031  0.831572  0.380024   \n",
       "94  0.506963  0.483484  0.417078  ...  0.579118  0.587216  0.574139  0.729981   \n",
       "95  0.491012  0.502300  0.388003  ...  0.417008  0.412433  0.400359  0.338844   \n",
       "\n",
       "        13_y      14_y      15_y      16_y      17_y  Y  \n",
       "0   0.492199  0.552743  0.490987  0.564235  0.489883  0  \n",
       "1   0.463085  0.507366  0.448752  0.511667  0.434354  0  \n",
       "2   0.610946  0.498965  0.643391  0.495000  0.678543  0  \n",
       "3   0.474913  0.346625  0.487613  0.319134  0.507263  0  \n",
       "4   0.482137  0.591745  0.482272  0.614701  0.470514  0  \n",
       "..       ...       ...       ...       ...       ... ..  \n",
       "91  0.268853  0.527715  0.553091  0.381434  0.422276  1  \n",
       "92  0.631184  0.520522  0.423227  0.661199  0.525378  1  \n",
       "93  0.262156  0.575911  0.483287  0.470470  0.330142  1  \n",
       "94  0.651935  0.581281  0.571586  0.655428  0.641182  1  \n",
       "95  0.260979  0.428291  0.424024  0.353666  0.351520  1  \n",
       "\n",
       "[96 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('squatTrainSet.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>10_x</th>\n",
       "      <th>...</th>\n",
       "      <th>9_y</th>\n",
       "      <th>10_y</th>\n",
       "      <th>11_y</th>\n",
       "      <th>12_y</th>\n",
       "      <th>13_y</th>\n",
       "      <th>14_y</th>\n",
       "      <th>15_y</th>\n",
       "      <th>16_y</th>\n",
       "      <th>17_y</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_x</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.952709</td>\n",
       "      <td>0.956751</td>\n",
       "      <td>0.583042</td>\n",
       "      <td>0.588549</td>\n",
       "      <td>0.567609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224039</td>\n",
       "      <td>-0.104012</td>\n",
       "      <td>0.121761</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>-0.076732</td>\n",
       "      <td>0.138374</td>\n",
       "      <td>-0.164113</td>\n",
       "      <td>0.215662</td>\n",
       "      <td>0.341673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_x</th>\n",
       "      <td>0.998039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>0.943564</td>\n",
       "      <td>0.947252</td>\n",
       "      <td>0.572502</td>\n",
       "      <td>0.578259</td>\n",
       "      <td>0.575627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234923</td>\n",
       "      <td>-0.097371</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>-0.079874</td>\n",
       "      <td>0.104086</td>\n",
       "      <td>-0.093967</td>\n",
       "      <td>0.155911</td>\n",
       "      <td>-0.176812</td>\n",
       "      <td>0.219017</td>\n",
       "      <td>0.300589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_x</th>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>0.941172</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>0.569052</td>\n",
       "      <td>0.576690</td>\n",
       "      <td>0.576046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235410</td>\n",
       "      <td>-0.100278</td>\n",
       "      <td>0.129614</td>\n",
       "      <td>-0.084265</td>\n",
       "      <td>0.101632</td>\n",
       "      <td>-0.098475</td>\n",
       "      <td>0.159378</td>\n",
       "      <td>-0.182077</td>\n",
       "      <td>0.220013</td>\n",
       "      <td>0.298172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_x</th>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.954678</td>\n",
       "      <td>0.956737</td>\n",
       "      <td>0.602861</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0.590388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.105833</td>\n",
       "      <td>0.119764</td>\n",
       "      <td>-0.064791</td>\n",
       "      <td>0.113489</td>\n",
       "      <td>-0.085685</td>\n",
       "      <td>0.141903</td>\n",
       "      <td>-0.166237</td>\n",
       "      <td>0.222908</td>\n",
       "      <td>0.310731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_x</th>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.957361</td>\n",
       "      <td>0.592259</td>\n",
       "      <td>0.601820</td>\n",
       "      <td>0.584815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>-0.088387</td>\n",
       "      <td>0.136466</td>\n",
       "      <td>-0.095793</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>-0.188734</td>\n",
       "      <td>0.201952</td>\n",
       "      <td>0.309453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_x</th>\n",
       "      <td>0.952709</td>\n",
       "      <td>0.943564</td>\n",
       "      <td>0.941172</td>\n",
       "      <td>0.954678</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983856</td>\n",
       "      <td>0.751357</td>\n",
       "      <td>0.742581</td>\n",
       "      <td>0.634628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173009</td>\n",
       "      <td>-0.064274</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>-0.036414</td>\n",
       "      <td>0.060884</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>-0.104399</td>\n",
       "      <td>0.133075</td>\n",
       "      <td>0.466240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_x</th>\n",
       "      <td>0.956751</td>\n",
       "      <td>0.947252</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>0.956737</td>\n",
       "      <td>0.957361</td>\n",
       "      <td>0.983856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732863</td>\n",
       "      <td>0.748849</td>\n",
       "      <td>0.621902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156591</td>\n",
       "      <td>-0.090410</td>\n",
       "      <td>0.095773</td>\n",
       "      <td>-0.036250</td>\n",
       "      <td>0.064012</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.141819</td>\n",
       "      <td>0.472527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_x</th>\n",
       "      <td>0.583042</td>\n",
       "      <td>0.572502</td>\n",
       "      <td>0.569052</td>\n",
       "      <td>0.602861</td>\n",
       "      <td>0.592259</td>\n",
       "      <td>0.751357</td>\n",
       "      <td>0.732863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>0.735120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>-0.037885</td>\n",
       "      <td>0.044048</td>\n",
       "      <td>0.087686</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>0.276466</td>\n",
       "      <td>-0.248980</td>\n",
       "      <td>0.104131</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.397643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_x</th>\n",
       "      <td>0.588549</td>\n",
       "      <td>0.578259</td>\n",
       "      <td>0.576690</td>\n",
       "      <td>0.604431</td>\n",
       "      <td>0.601820</td>\n",
       "      <td>0.742581</td>\n",
       "      <td>0.748849</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>0.070537</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.026877</td>\n",
       "      <td>0.264549</td>\n",
       "      <td>-0.233267</td>\n",
       "      <td>0.039490</td>\n",
       "      <td>-0.044752</td>\n",
       "      <td>0.403667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_x</th>\n",
       "      <td>0.567609</td>\n",
       "      <td>0.575627</td>\n",
       "      <td>0.576046</td>\n",
       "      <td>0.590388</td>\n",
       "      <td>0.584815</td>\n",
       "      <td>0.634628</td>\n",
       "      <td>0.621902</td>\n",
       "      <td>0.735120</td>\n",
       "      <td>0.722057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147299</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.037156</td>\n",
       "      <td>-0.011528</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>0.087406</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>-0.032226</td>\n",
       "      <td>0.074473</td>\n",
       "      <td>0.105376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_x</th>\n",
       "      <td>0.565680</td>\n",
       "      <td>0.571988</td>\n",
       "      <td>0.572778</td>\n",
       "      <td>0.585913</td>\n",
       "      <td>0.581263</td>\n",
       "      <td>0.629292</td>\n",
       "      <td>0.626186</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.731385</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104965</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.087604</td>\n",
       "      <td>-0.062874</td>\n",
       "      <td>-0.018180</td>\n",
       "      <td>0.066193</td>\n",
       "      <td>0.111526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_x</th>\n",
       "      <td>0.592896</td>\n",
       "      <td>0.563546</td>\n",
       "      <td>0.560138</td>\n",
       "      <td>0.586273</td>\n",
       "      <td>0.585481</td>\n",
       "      <td>0.739177</td>\n",
       "      <td>0.731525</td>\n",
       "      <td>0.660718</td>\n",
       "      <td>0.668065</td>\n",
       "      <td>0.346804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>-0.123424</td>\n",
       "      <td>0.121921</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.075731</td>\n",
       "      <td>0.165352</td>\n",
       "      <td>-0.110586</td>\n",
       "      <td>-0.051576</td>\n",
       "      <td>0.105997</td>\n",
       "      <td>0.696326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_x</th>\n",
       "      <td>0.589419</td>\n",
       "      <td>0.559769</td>\n",
       "      <td>0.557102</td>\n",
       "      <td>0.581537</td>\n",
       "      <td>0.584472</td>\n",
       "      <td>0.730986</td>\n",
       "      <td>0.736356</td>\n",
       "      <td>0.655980</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.349397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114082</td>\n",
       "      <td>-0.102836</td>\n",
       "      <td>0.137604</td>\n",
       "      <td>-0.044241</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>0.167728</td>\n",
       "      <td>-0.115771</td>\n",
       "      <td>-0.072006</td>\n",
       "      <td>0.079358</td>\n",
       "      <td>0.697033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_x</th>\n",
       "      <td>-0.441769</td>\n",
       "      <td>-0.429084</td>\n",
       "      <td>-0.429517</td>\n",
       "      <td>-0.423544</td>\n",
       "      <td>-0.425981</td>\n",
       "      <td>-0.453444</td>\n",
       "      <td>-0.459870</td>\n",
       "      <td>-0.349964</td>\n",
       "      <td>-0.379003</td>\n",
       "      <td>-0.293631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207105</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>-0.181313</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.087606</td>\n",
       "      <td>-0.080883</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.087392</td>\n",
       "      <td>0.017283</td>\n",
       "      <td>-0.602592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_x</th>\n",
       "      <td>-0.431585</td>\n",
       "      <td>-0.416593</td>\n",
       "      <td>-0.417294</td>\n",
       "      <td>-0.414643</td>\n",
       "      <td>-0.407054</td>\n",
       "      <td>-0.440863</td>\n",
       "      <td>-0.446945</td>\n",
       "      <td>-0.375400</td>\n",
       "      <td>-0.372154</td>\n",
       "      <td>-0.292173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128264</td>\n",
       "      <td>0.128277</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.111324</td>\n",
       "      <td>-0.094345</td>\n",
       "      <td>-0.100148</td>\n",
       "      <td>0.031371</td>\n",
       "      <td>-0.068749</td>\n",
       "      <td>-0.106134</td>\n",
       "      <td>-0.591942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_x</th>\n",
       "      <td>-0.632029</td>\n",
       "      <td>-0.647903</td>\n",
       "      <td>-0.649369</td>\n",
       "      <td>-0.636863</td>\n",
       "      <td>-0.646078</td>\n",
       "      <td>-0.555656</td>\n",
       "      <td>-0.564256</td>\n",
       "      <td>-0.311042</td>\n",
       "      <td>-0.341626</td>\n",
       "      <td>-0.463958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291666</td>\n",
       "      <td>-0.063608</td>\n",
       "      <td>-0.225808</td>\n",
       "      <td>0.212051</td>\n",
       "      <td>0.094605</td>\n",
       "      <td>0.131388</td>\n",
       "      <td>-0.197203</td>\n",
       "      <td>0.270099</td>\n",
       "      <td>-0.052354</td>\n",
       "      <td>-0.189415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_x</th>\n",
       "      <td>-0.636251</td>\n",
       "      <td>-0.647424</td>\n",
       "      <td>-0.648953</td>\n",
       "      <td>-0.646465</td>\n",
       "      <td>-0.633328</td>\n",
       "      <td>-0.553761</td>\n",
       "      <td>-0.560282</td>\n",
       "      <td>-0.342377</td>\n",
       "      <td>-0.318922</td>\n",
       "      <td>-0.461896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182610</td>\n",
       "      <td>0.203085</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>-0.116758</td>\n",
       "      <td>-0.235379</td>\n",
       "      <td>0.153117</td>\n",
       "      <td>-0.189531</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>-0.318426</td>\n",
       "      <td>-0.182338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_y</th>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>-0.024182</td>\n",
       "      <td>-0.005140</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.031391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308097</td>\n",
       "      <td>0.377565</td>\n",
       "      <td>0.370423</td>\n",
       "      <td>-0.194667</td>\n",
       "      <td>-0.194687</td>\n",
       "      <td>0.399441</td>\n",
       "      <td>0.356519</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>-0.047790</td>\n",
       "      <td>-0.001403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_y</th>\n",
       "      <td>-0.038061</td>\n",
       "      <td>-0.035360</td>\n",
       "      <td>-0.039465</td>\n",
       "      <td>-0.042510</td>\n",
       "      <td>-0.027787</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>-0.051154</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207074</td>\n",
       "      <td>0.350241</td>\n",
       "      <td>0.263931</td>\n",
       "      <td>-0.087185</td>\n",
       "      <td>-0.141095</td>\n",
       "      <td>0.504292</td>\n",
       "      <td>0.285136</td>\n",
       "      <td>0.123655</td>\n",
       "      <td>-0.048275</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_y</th>\n",
       "      <td>0.041950</td>\n",
       "      <td>0.047612</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.036540</td>\n",
       "      <td>0.051565</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>-0.002977</td>\n",
       "      <td>-0.017273</td>\n",
       "      <td>-0.016235</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369515</td>\n",
       "      <td>0.263303</td>\n",
       "      <td>0.347406</td>\n",
       "      <td>-0.147198</td>\n",
       "      <td>-0.080523</td>\n",
       "      <td>0.325745</td>\n",
       "      <td>0.471984</td>\n",
       "      <td>-0.009886</td>\n",
       "      <td>0.105435</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_y</th>\n",
       "      <td>-0.083785</td>\n",
       "      <td>-0.088091</td>\n",
       "      <td>-0.092618</td>\n",
       "      <td>-0.082418</td>\n",
       "      <td>-0.091614</td>\n",
       "      <td>-0.021421</td>\n",
       "      <td>-0.074711</td>\n",
       "      <td>0.057678</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081044</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>-0.170472</td>\n",
       "      <td>0.413520</td>\n",
       "      <td>0.269228</td>\n",
       "      <td>0.620484</td>\n",
       "      <td>0.115376</td>\n",
       "      <td>0.587099</td>\n",
       "      <td>0.179473</td>\n",
       "      <td>-0.008896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_y</th>\n",
       "      <td>0.097904</td>\n",
       "      <td>0.099563</td>\n",
       "      <td>0.098159</td>\n",
       "      <td>0.096881</td>\n",
       "      <td>0.087781</td>\n",
       "      <td>0.081160</td>\n",
       "      <td>0.034719</td>\n",
       "      <td>-0.002960</td>\n",
       "      <td>-0.034674</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342031</td>\n",
       "      <td>-0.186473</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.265539</td>\n",
       "      <td>0.440107</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>0.587545</td>\n",
       "      <td>0.239917</td>\n",
       "      <td>0.582226</td>\n",
       "      <td>0.018799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_y</th>\n",
       "      <td>-0.208310</td>\n",
       "      <td>-0.219507</td>\n",
       "      <td>-0.226194</td>\n",
       "      <td>-0.202636</td>\n",
       "      <td>-0.222259</td>\n",
       "      <td>-0.100392</td>\n",
       "      <td>-0.142274</td>\n",
       "      <td>0.112494</td>\n",
       "      <td>0.030076</td>\n",
       "      <td>-0.009669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322063</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>-0.384426</td>\n",
       "      <td>0.669838</td>\n",
       "      <td>0.335984</td>\n",
       "      <td>0.709643</td>\n",
       "      <td>-0.261953</td>\n",
       "      <td>0.830128</td>\n",
       "      <td>0.039992</td>\n",
       "      <td>0.006609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_y</th>\n",
       "      <td>0.239486</td>\n",
       "      <td>0.245339</td>\n",
       "      <td>0.244947</td>\n",
       "      <td>0.239620</td>\n",
       "      <td>0.222154</td>\n",
       "      <td>0.156880</td>\n",
       "      <td>0.129136</td>\n",
       "      <td>-0.024359</td>\n",
       "      <td>-0.067782</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>-0.371119</td>\n",
       "      <td>0.112466</td>\n",
       "      <td>0.324312</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>-0.233046</td>\n",
       "      <td>0.714950</td>\n",
       "      <td>0.088145</td>\n",
       "      <td>0.848158</td>\n",
       "      <td>0.010294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_y</th>\n",
       "      <td>-0.197440</td>\n",
       "      <td>-0.199029</td>\n",
       "      <td>-0.203705</td>\n",
       "      <td>-0.198965</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.117342</td>\n",
       "      <td>-0.142914</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>-0.007473</td>\n",
       "      <td>-0.092103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042015</td>\n",
       "      <td>0.810877</td>\n",
       "      <td>0.239810</td>\n",
       "      <td>-0.028256</td>\n",
       "      <td>-0.365860</td>\n",
       "      <td>0.669449</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>0.311317</td>\n",
       "      <td>-0.520879</td>\n",
       "      <td>-0.048657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_y</th>\n",
       "      <td>0.224039</td>\n",
       "      <td>0.234923</td>\n",
       "      <td>0.235410</td>\n",
       "      <td>0.228198</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>0.173009</td>\n",
       "      <td>0.156591</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>0.147299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230420</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>-0.339347</td>\n",
       "      <td>-0.004345</td>\n",
       "      <td>-0.310763</td>\n",
       "      <td>0.677365</td>\n",
       "      <td>-0.482842</td>\n",
       "      <td>0.361664</td>\n",
       "      <td>0.070515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_y</th>\n",
       "      <td>-0.104012</td>\n",
       "      <td>-0.097371</td>\n",
       "      <td>-0.100278</td>\n",
       "      <td>-0.105833</td>\n",
       "      <td>-0.088387</td>\n",
       "      <td>-0.064274</td>\n",
       "      <td>-0.090410</td>\n",
       "      <td>-0.037885</td>\n",
       "      <td>-0.033608</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557468</td>\n",
       "      <td>-0.414418</td>\n",
       "      <td>-0.615452</td>\n",
       "      <td>0.360414</td>\n",
       "      <td>-0.109192</td>\n",
       "      <td>-0.151245</td>\n",
       "      <td>-0.564731</td>\n",
       "      <td>-0.074850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_y</th>\n",
       "      <td>0.121761</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>0.129614</td>\n",
       "      <td>0.119764</td>\n",
       "      <td>0.136466</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.095773</td>\n",
       "      <td>0.044048</td>\n",
       "      <td>0.070537</td>\n",
       "      <td>0.037156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.557468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.620337</td>\n",
       "      <td>-0.428816</td>\n",
       "      <td>-0.110760</td>\n",
       "      <td>0.385957</td>\n",
       "      <td>-0.584657</td>\n",
       "      <td>-0.110985</td>\n",
       "      <td>0.094309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_y</th>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.079874</td>\n",
       "      <td>-0.084265</td>\n",
       "      <td>-0.064791</td>\n",
       "      <td>-0.095793</td>\n",
       "      <td>-0.036414</td>\n",
       "      <td>-0.036250</td>\n",
       "      <td>0.087686</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.011528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339347</td>\n",
       "      <td>-0.414418</td>\n",
       "      <td>-0.620337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838302</td>\n",
       "      <td>0.176672</td>\n",
       "      <td>-0.217986</td>\n",
       "      <td>0.813845</td>\n",
       "      <td>0.474736</td>\n",
       "      <td>0.053299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_y</th>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.104086</td>\n",
       "      <td>0.101632</td>\n",
       "      <td>0.113489</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.060884</td>\n",
       "      <td>0.064012</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>-0.026877</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004345</td>\n",
       "      <td>-0.615452</td>\n",
       "      <td>-0.428816</td>\n",
       "      <td>0.838302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200480</td>\n",
       "      <td>0.181325</td>\n",
       "      <td>0.504195</td>\n",
       "      <td>0.812456</td>\n",
       "      <td>-0.027717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_y</th>\n",
       "      <td>-0.076732</td>\n",
       "      <td>-0.093967</td>\n",
       "      <td>-0.098475</td>\n",
       "      <td>-0.085685</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.276466</td>\n",
       "      <td>0.264549</td>\n",
       "      <td>0.087406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310763</td>\n",
       "      <td>0.360414</td>\n",
       "      <td>-0.110760</td>\n",
       "      <td>0.176672</td>\n",
       "      <td>-0.200480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.458620</td>\n",
       "      <td>0.616636</td>\n",
       "      <td>-0.409062</td>\n",
       "      <td>0.204168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_y</th>\n",
       "      <td>0.138374</td>\n",
       "      <td>0.155911</td>\n",
       "      <td>0.159378</td>\n",
       "      <td>0.141903</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.248980</td>\n",
       "      <td>-0.233267</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677365</td>\n",
       "      <td>-0.109192</td>\n",
       "      <td>0.385957</td>\n",
       "      <td>-0.217986</td>\n",
       "      <td>0.181325</td>\n",
       "      <td>-0.458620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.414223</td>\n",
       "      <td>0.643928</td>\n",
       "      <td>-0.147063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_y</th>\n",
       "      <td>-0.164113</td>\n",
       "      <td>-0.176812</td>\n",
       "      <td>-0.182077</td>\n",
       "      <td>-0.166237</td>\n",
       "      <td>-0.188734</td>\n",
       "      <td>-0.104399</td>\n",
       "      <td>-0.104989</td>\n",
       "      <td>0.104131</td>\n",
       "      <td>0.039490</td>\n",
       "      <td>-0.032226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482842</td>\n",
       "      <td>-0.151245</td>\n",
       "      <td>-0.584657</td>\n",
       "      <td>0.813845</td>\n",
       "      <td>0.504195</td>\n",
       "      <td>0.616636</td>\n",
       "      <td>-0.414223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102966</td>\n",
       "      <td>0.028712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_y</th>\n",
       "      <td>0.215662</td>\n",
       "      <td>0.219017</td>\n",
       "      <td>0.220013</td>\n",
       "      <td>0.222908</td>\n",
       "      <td>0.201952</td>\n",
       "      <td>0.133075</td>\n",
       "      <td>0.141819</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>-0.044752</td>\n",
       "      <td>0.074473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361664</td>\n",
       "      <td>-0.564731</td>\n",
       "      <td>-0.110985</td>\n",
       "      <td>0.474736</td>\n",
       "      <td>0.812456</td>\n",
       "      <td>-0.409062</td>\n",
       "      <td>0.643928</td>\n",
       "      <td>0.102966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.341673</td>\n",
       "      <td>0.300589</td>\n",
       "      <td>0.298172</td>\n",
       "      <td>0.310731</td>\n",
       "      <td>0.309453</td>\n",
       "      <td>0.466240</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.397643</td>\n",
       "      <td>0.403667</td>\n",
       "      <td>0.105376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>-0.074850</td>\n",
       "      <td>0.094309</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>-0.027717</td>\n",
       "      <td>0.204168</td>\n",
       "      <td>-0.147063</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>-0.002311</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1_x       2_x       3_x       4_x       5_x       6_x       7_x  \\\n",
       "1_x   1.000000  0.998039  0.997844  0.995700  0.994926  0.952709  0.956751   \n",
       "2_x   0.998039  1.000000  0.999667  0.997437  0.996860  0.943564  0.947252   \n",
       "3_x   0.997844  0.999667  1.000000  0.996829  0.996853  0.941172  0.946170   \n",
       "4_x   0.995700  0.997437  0.996829  1.000000  0.997696  0.954678  0.956737   \n",
       "5_x   0.994926  0.996860  0.996853  0.997696  1.000000  0.951815  0.957361   \n",
       "6_x   0.952709  0.943564  0.941172  0.954678  0.951815  1.000000  0.983856   \n",
       "7_x   0.956751  0.947252  0.946170  0.956737  0.957361  0.983856  1.000000   \n",
       "8_x   0.583042  0.572502  0.569052  0.602861  0.592259  0.751357  0.732863   \n",
       "9_x   0.588549  0.578259  0.576690  0.604431  0.601820  0.742581  0.748849   \n",
       "10_x  0.567609  0.575627  0.576046  0.590388  0.584815  0.634628  0.621902   \n",
       "11_x  0.565680  0.571988  0.572778  0.585913  0.581263  0.629292  0.626186   \n",
       "12_x  0.592896  0.563546  0.560138  0.586273  0.585481  0.739177  0.731525   \n",
       "13_x  0.589419  0.559769  0.557102  0.581537  0.584472  0.730986  0.736356   \n",
       "14_x -0.441769 -0.429084 -0.429517 -0.423544 -0.425981 -0.453444 -0.459870   \n",
       "15_x -0.431585 -0.416593 -0.417294 -0.414643 -0.407054 -0.440863 -0.446945   \n",
       "16_x -0.632029 -0.647903 -0.649369 -0.636863 -0.646078 -0.555656 -0.564256   \n",
       "17_x -0.636251 -0.647424 -0.648953 -0.646465 -0.633328 -0.553761 -0.560282   \n",
       "1_y   0.004096  0.009630  0.006045 -0.001397  0.018088  0.048395 -0.024182   \n",
       "2_y  -0.038061 -0.035360 -0.039465 -0.042510 -0.027787  0.019871 -0.051154   \n",
       "3_y   0.041950  0.047612  0.044681  0.036540  0.051565  0.065654 -0.002977   \n",
       "4_y  -0.083785 -0.088091 -0.092618 -0.082418 -0.091614 -0.021421 -0.074711   \n",
       "5_y   0.097904  0.099563  0.098159  0.096881  0.087781  0.081160  0.034719   \n",
       "6_y  -0.208310 -0.219507 -0.226194 -0.202636 -0.222259 -0.100392 -0.142274   \n",
       "7_y   0.239486  0.245339  0.244947  0.239620  0.222154  0.156880  0.129136   \n",
       "8_y  -0.197440 -0.199029 -0.203705 -0.198965 -0.193001 -0.117342 -0.142914   \n",
       "9_y   0.224039  0.234923  0.235410  0.228198  0.232072  0.173009  0.156591   \n",
       "10_y -0.104012 -0.097371 -0.100278 -0.105833 -0.088387 -0.064274 -0.090410   \n",
       "11_y  0.121761  0.129010  0.129614  0.119764  0.136466  0.116608  0.095773   \n",
       "12_y -0.067104 -0.079874 -0.084265 -0.064791 -0.095793 -0.036414 -0.036250   \n",
       "13_y  0.104824  0.104086  0.101632  0.113489  0.084356  0.060884  0.064012   \n",
       "14_y -0.076732 -0.093967 -0.098475 -0.085685 -0.083430  0.060999  0.038773   \n",
       "15_y  0.138374  0.155911  0.159378  0.141903  0.145055  0.015900  0.003441   \n",
       "16_y -0.164113 -0.176812 -0.182077 -0.166237 -0.188734 -0.104399 -0.104989   \n",
       "17_y  0.215662  0.219017  0.220013  0.222908  0.201952  0.133075  0.141819   \n",
       "Y     0.341673  0.300589  0.298172  0.310731  0.309453  0.466240  0.472527   \n",
       "\n",
       "           8_x       9_x      10_x  ...       9_y      10_y      11_y  \\\n",
       "1_x   0.583042  0.588549  0.567609  ...  0.224039 -0.104012  0.121761   \n",
       "2_x   0.572502  0.578259  0.575627  ...  0.234923 -0.097371  0.129010   \n",
       "3_x   0.569052  0.576690  0.576046  ...  0.235410 -0.100278  0.129614   \n",
       "4_x   0.602861  0.604431  0.590388  ...  0.228198 -0.105833  0.119764   \n",
       "5_x   0.592259  0.601820  0.584815  ...  0.232072 -0.088387  0.136466   \n",
       "6_x   0.751357  0.742581  0.634628  ...  0.173009 -0.064274  0.116608   \n",
       "7_x   0.732863  0.748849  0.621902  ...  0.156591 -0.090410  0.095773   \n",
       "8_x   1.000000  0.975522  0.735120  ...  0.031899 -0.037885  0.044048   \n",
       "9_x   0.975522  1.000000  0.722057  ...  0.024481 -0.033608  0.070537   \n",
       "10_x  0.735120  0.722057  1.000000  ...  0.147299  0.010622  0.037156   \n",
       "11_x  0.733013  0.731385  0.988333  ...  0.104965  0.003374  0.001604   \n",
       "12_x  0.660718  0.668065  0.346804  ...  0.116329 -0.123424  0.121921   \n",
       "13_x  0.655980  0.679000  0.349397  ...  0.114082 -0.102836  0.137604   \n",
       "14_x -0.349964 -0.379003 -0.293631  ... -0.207105 -0.019305 -0.181313   \n",
       "15_x -0.375400 -0.372154 -0.292173  ... -0.128264  0.128277 -0.020475   \n",
       "16_x -0.311042 -0.341626 -0.463958  ... -0.291666 -0.063608 -0.225808   \n",
       "17_x -0.342377 -0.318922 -0.461896  ... -0.182610  0.203085  0.048680   \n",
       "1_y  -0.005140 -0.002394  0.031391  ...  0.308097  0.377565  0.370423   \n",
       "2_y   0.006041 -0.000553  0.018775  ...  0.207074  0.350241  0.263931   \n",
       "3_y  -0.017273 -0.016235  0.029564  ...  0.369515  0.263303  0.347406   \n",
       "4_y   0.057678  0.006169  0.022306  ... -0.081044  0.052027 -0.170472   \n",
       "5_y  -0.002960 -0.034674  0.032634  ...  0.342031 -0.186473  0.052771   \n",
       "6_y   0.112494  0.030076 -0.009669  ... -0.322063  0.095570 -0.384426   \n",
       "7_y  -0.024359 -0.067782  0.054557  ...  0.541702 -0.371119  0.112466   \n",
       "8_y   0.022007 -0.007473 -0.092103  ... -0.042015  0.810877  0.239810   \n",
       "9_y   0.031899  0.024481  0.147299  ...  1.000000  0.230420  0.808456   \n",
       "10_y -0.037885 -0.033608  0.010622  ...  0.230420  1.000000  0.557468   \n",
       "11_y  0.044048  0.070537  0.037156  ...  0.808456  0.557468  1.000000   \n",
       "12_y  0.087686 -0.002592 -0.011528  ... -0.339347 -0.414418 -0.620337   \n",
       "13_y  0.048325 -0.026877  0.027760  ... -0.004345 -0.615452 -0.428816   \n",
       "14_y  0.276466  0.264549  0.087406  ... -0.310763  0.360414 -0.110760   \n",
       "15_y -0.248980 -0.233267 -0.033764  ...  0.677365 -0.109192  0.385957   \n",
       "16_y  0.104131  0.039490 -0.032226  ... -0.482842 -0.151245 -0.584657   \n",
       "17_y -0.010359 -0.044752  0.074473  ...  0.361664 -0.564731 -0.110985   \n",
       "Y     0.397643  0.403667  0.105376  ...  0.070515 -0.074850  0.094309   \n",
       "\n",
       "          12_y      13_y      14_y      15_y      16_y      17_y         Y  \n",
       "1_x  -0.067104  0.104824 -0.076732  0.138374 -0.164113  0.215662  0.341673  \n",
       "2_x  -0.079874  0.104086 -0.093967  0.155911 -0.176812  0.219017  0.300589  \n",
       "3_x  -0.084265  0.101632 -0.098475  0.159378 -0.182077  0.220013  0.298172  \n",
       "4_x  -0.064791  0.113489 -0.085685  0.141903 -0.166237  0.222908  0.310731  \n",
       "5_x  -0.095793  0.084356 -0.083430  0.145055 -0.188734  0.201952  0.309453  \n",
       "6_x  -0.036414  0.060884  0.060999  0.015900 -0.104399  0.133075  0.466240  \n",
       "7_x  -0.036250  0.064012  0.038773  0.003441 -0.104989  0.141819  0.472527  \n",
       "8_x   0.087686  0.048325  0.276466 -0.248980  0.104131 -0.010359  0.397643  \n",
       "9_x  -0.002592 -0.026877  0.264549 -0.233267  0.039490 -0.044752  0.403667  \n",
       "10_x -0.011528  0.027760  0.087406 -0.033764 -0.032226  0.074473  0.105376  \n",
       "11_x  0.008075  0.035826  0.087604 -0.062874 -0.018180  0.066193  0.111526  \n",
       "12_x -0.004365  0.075731  0.165352 -0.110586 -0.051576  0.105997  0.696326  \n",
       "13_x -0.044241  0.032529  0.167728 -0.115771 -0.072006  0.079358  0.697033  \n",
       "14_x  0.077215  0.087606 -0.080883  0.010108  0.087392  0.017283 -0.602592  \n",
       "15_x -0.111324 -0.094345 -0.100148  0.031371 -0.068749 -0.106134 -0.591942  \n",
       "16_x  0.212051  0.094605  0.131388 -0.197203  0.270099 -0.052354 -0.189415  \n",
       "17_x -0.116758 -0.235379  0.153117 -0.189531  0.014515 -0.318426 -0.182338  \n",
       "1_y  -0.194667 -0.194687  0.399441  0.356519 -0.016000 -0.047790 -0.001403  \n",
       "2_y  -0.087185 -0.141095  0.504292  0.285136  0.123655 -0.048275  0.001488  \n",
       "3_y  -0.147198 -0.080523  0.325745  0.471984 -0.009886  0.105435  0.001987  \n",
       "4_y   0.413520  0.269228  0.620484  0.115376  0.587099  0.179473 -0.008896  \n",
       "5_y   0.265539  0.440107  0.154313  0.587545  0.239917  0.582226  0.018799  \n",
       "6_y   0.669838  0.335984  0.709643 -0.261953  0.830128  0.039992  0.006609  \n",
       "7_y   0.324312  0.673797 -0.233046  0.714950  0.088145  0.848158  0.010294  \n",
       "8_y  -0.028256 -0.365860  0.669449 -0.332775  0.311317 -0.520879 -0.048657  \n",
       "9_y  -0.339347 -0.004345 -0.310763  0.677365 -0.482842  0.361664  0.070515  \n",
       "10_y -0.414418 -0.615452  0.360414 -0.109192 -0.151245 -0.564731 -0.074850  \n",
       "11_y -0.620337 -0.428816 -0.110760  0.385957 -0.584657 -0.110985  0.094309  \n",
       "12_y  1.000000  0.838302  0.176672 -0.217986  0.813845  0.474736  0.053299  \n",
       "13_y  0.838302  1.000000 -0.200480  0.181325  0.504195  0.812456 -0.027717  \n",
       "14_y  0.176672 -0.200480  1.000000 -0.458620  0.616636 -0.409062  0.204168  \n",
       "15_y -0.217986  0.181325 -0.458620  1.000000 -0.414223  0.643928 -0.147063  \n",
       "16_y  0.813845  0.504195  0.616636 -0.414223  1.000000  0.102966  0.028712  \n",
       "17_y  0.474736  0.812456 -0.409062  0.643928  0.102966  1.000000 -0.002311  \n",
       "Y     0.053299 -0.027717  0.204168 -0.147063  0.028712 -0.002311  1.000000  \n",
       "\n",
       "[35 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in columns if col != \"Y\"]\n",
    "x_df = df[x_cols]\n",
    "y_df = df[['Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2001l\\AppData\\Local\\Temp\\ipykernel_25692\\2561977078.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_df['Y'] = y_df['Y'].astype('int')\n"
     ]
    }
   ],
   "source": [
    "y_df['Y'] = y_df['Y'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2001l\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6610 - loss: 0.6760 - val_accuracy: 0.0000e+00 - val_loss: 0.8523\n",
      "Epoch 2/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6702 - loss: 0.6410 - val_accuracy: 0.0000e+00 - val_loss: 0.9780\n",
      "Epoch 3/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7327 - loss: 0.5990 - val_accuracy: 0.0000e+00 - val_loss: 1.0806\n",
      "Epoch 4/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6859 - loss: 0.6142 - val_accuracy: 0.0000e+00 - val_loss: 1.1184\n",
      "Epoch 5/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6468 - loss: 0.6410 - val_accuracy: 0.0000e+00 - val_loss: 1.1307\n",
      "Epoch 6/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6585 - loss: 0.6290 - val_accuracy: 0.0000e+00 - val_loss: 1.1495\n",
      "Epoch 7/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7171 - loss: 0.5807 - val_accuracy: 0.0000e+00 - val_loss: 1.1695\n",
      "Epoch 8/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6546 - loss: 0.6301 - val_accuracy: 0.0000e+00 - val_loss: 1.1572\n",
      "Epoch 9/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6702 - loss: 0.6127 - val_accuracy: 0.0000e+00 - val_loss: 1.1619\n",
      "Epoch 10/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6859 - loss: 0.5959 - val_accuracy: 0.0000e+00 - val_loss: 1.1697\n",
      "Epoch 11/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6546 - loss: 0.6170 - val_accuracy: 0.0000e+00 - val_loss: 1.1494\n",
      "Epoch 12/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6819 - loss: 0.5887 - val_accuracy: 0.0000e+00 - val_loss: 1.1459\n",
      "Epoch 13/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6702 - loss: 0.6017 - val_accuracy: 0.0000e+00 - val_loss: 1.1298\n",
      "Epoch 14/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6546 - loss: 0.6081 - val_accuracy: 0.0000e+00 - val_loss: 1.1022\n",
      "Epoch 15/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7054 - loss: 0.5723 - val_accuracy: 0.0000e+00 - val_loss: 1.0993\n",
      "Epoch 16/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6819 - loss: 0.5776 - val_accuracy: 0.0000e+00 - val_loss: 1.0622\n",
      "Epoch 17/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6976 - loss: 0.5741 - val_accuracy: 0.0000e+00 - val_loss: 1.0288\n",
      "Epoch 18/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6624 - loss: 0.5912 - val_accuracy: 0.0000e+00 - val_loss: 1.0088\n",
      "Epoch 19/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6702 - loss: 0.5805 - val_accuracy: 0.0000e+00 - val_loss: 1.0101\n",
      "Epoch 20/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6819 - loss: 0.5764 - val_accuracy: 0.0000e+00 - val_loss: 1.0268\n",
      "Epoch 21/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6780 - loss: 0.5774 - val_accuracy: 0.0000e+00 - val_loss: 1.0267\n",
      "Epoch 22/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7002 - loss: 0.5581 - val_accuracy: 0.0000e+00 - val_loss: 1.0240\n",
      "Epoch 23/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7185 - loss: 0.5602 - val_accuracy: 0.0000e+00 - val_loss: 0.9976\n",
      "Epoch 24/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7317 - loss: 0.5441 - val_accuracy: 0.0500 - val_loss: 0.9595\n",
      "Epoch 25/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7786 - loss: 0.5277 - val_accuracy: 0.0500 - val_loss: 0.9570\n",
      "Epoch 26/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7317 - loss: 0.5596 - val_accuracy: 0.0500 - val_loss: 0.9589\n",
      "Epoch 27/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7239 - loss: 0.5540 - val_accuracy: 0.0500 - val_loss: 1.0075\n",
      "Epoch 28/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7434 - loss: 0.5393 - val_accuracy: 0.0000e+00 - val_loss: 1.0903\n",
      "Epoch 29/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7317 - loss: 0.5483 - val_accuracy: 0.0500 - val_loss: 1.1002\n",
      "Epoch 30/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7200 - loss: 0.5539 - val_accuracy: 0.0500 - val_loss: 1.0654\n",
      "Epoch 31/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7317 - loss: 0.5433 - val_accuracy: 0.0500 - val_loss: 1.0553\n",
      "Epoch 32/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7239 - loss: 0.5493 - val_accuracy: 0.0500 - val_loss: 1.0580\n",
      "Epoch 33/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7473 - loss: 0.5293 - val_accuracy: 0.0500 - val_loss: 1.0670\n",
      "Epoch 34/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7473 - loss: 0.5159 - val_accuracy: 0.0500 - val_loss: 1.0156\n",
      "Epoch 35/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7512 - loss: 0.5184 - val_accuracy: 0.1000 - val_loss: 0.9612\n",
      "Epoch 36/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7017 - loss: 0.5270 - val_accuracy: 0.1000 - val_loss: 0.9637\n",
      "Epoch 37/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7095 - loss: 0.5318 - val_accuracy: 0.1000 - val_loss: 1.0158\n",
      "Epoch 38/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7630 - loss: 0.4979 - val_accuracy: 0.0500 - val_loss: 1.0727\n",
      "Epoch 39/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7317 - loss: 0.5158 - val_accuracy: 0.0500 - val_loss: 1.0539\n",
      "Epoch 40/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7434 - loss: 0.5103 - val_accuracy: 0.1000 - val_loss: 1.0150\n",
      "Epoch 41/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7212 - loss: 0.5014 - val_accuracy: 0.1500 - val_loss: 0.9547\n",
      "Epoch 42/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7695 - loss: 0.5044 - val_accuracy: 0.3000 - val_loss: 0.9040\n",
      "Epoch 43/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7422 - loss: 0.5260 - val_accuracy: 0.3500 - val_loss: 0.8648\n",
      "Epoch 44/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7356 - loss: 0.5102 - val_accuracy: 0.3000 - val_loss: 0.9085\n",
      "Epoch 45/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7422 - loss: 0.5192 - val_accuracy: 0.1500 - val_loss: 0.9857\n",
      "Epoch 46/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6926 - loss: 0.5345 - val_accuracy: 0.1500 - val_loss: 1.0099\n",
      "Epoch 47/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7590 - loss: 0.4836 - val_accuracy: 0.1000 - val_loss: 1.0382\n",
      "Epoch 48/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7083 - loss: 0.5304 - val_accuracy: 0.2000 - val_loss: 0.9583\n",
      "Epoch 49/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7566 - loss: 0.5047 - val_accuracy: 0.2000 - val_loss: 0.9796\n",
      "Epoch 50/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7617 - loss: 0.4832 - val_accuracy: 0.2000 - val_loss: 0.9986\n",
      "Epoch 51/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7839 - loss: 0.4852 - val_accuracy: 0.2500 - val_loss: 0.9735\n",
      "Epoch 52/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7722 - loss: 0.4892 - val_accuracy: 0.3500 - val_loss: 0.8933\n",
      "Epoch 53/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7578 - loss: 0.5011 - val_accuracy: 0.4000 - val_loss: 0.8566\n",
      "Epoch 54/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7200 - loss: 0.5010 - val_accuracy: 0.3500 - val_loss: 0.8898\n",
      "Epoch 55/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7761 - loss: 0.4872 - val_accuracy: 0.2000 - val_loss: 1.0161\n",
      "Epoch 56/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7488 - loss: 0.5015 - val_accuracy: 0.1500 - val_loss: 1.0538\n",
      "Epoch 57/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7461 - loss: 0.4663 - val_accuracy: 0.2500 - val_loss: 1.0185\n",
      "Epoch 58/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7475 - loss: 0.5143 - val_accuracy: 0.3000 - val_loss: 0.9496\n",
      "Epoch 59/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7839 - loss: 0.4542 - val_accuracy: 0.2500 - val_loss: 0.9721\n",
      "Epoch 60/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7593 - loss: 0.4861 - val_accuracy: 0.2500 - val_loss: 0.9847\n",
      "Epoch 61/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7749 - loss: 0.4742 - val_accuracy: 0.2500 - val_loss: 0.9651\n",
      "Epoch 62/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 0.4638 - val_accuracy: 0.4000 - val_loss: 0.9100\n",
      "Epoch 63/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7905 - loss: 0.4693 - val_accuracy: 0.4000 - val_loss: 0.8705\n",
      "Epoch 64/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.4796 - val_accuracy: 0.3000 - val_loss: 0.9594\n",
      "Epoch 65/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8100 - loss: 0.4430 - val_accuracy: 0.2500 - val_loss: 1.0190\n",
      "Epoch 66/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7671 - loss: 0.4689 - val_accuracy: 0.4000 - val_loss: 0.9261\n",
      "Epoch 67/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8037 - loss: 0.4584 - val_accuracy: 0.4500 - val_loss: 0.8496\n",
      "Epoch 68/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8037 - loss: 0.4406 - val_accuracy: 0.4500 - val_loss: 0.8239\n",
      "Epoch 69/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8493 - loss: 0.4352 - val_accuracy: 0.4000 - val_loss: 0.8757\n",
      "Epoch 70/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8193 - loss: 0.4235 - val_accuracy: 0.4500 - val_loss: 0.8504\n",
      "Epoch 71/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.4535 - val_accuracy: 0.4500 - val_loss: 0.8053\n",
      "Epoch 72/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.4276 - val_accuracy: 0.4500 - val_loss: 0.8525\n",
      "Epoch 73/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8181 - loss: 0.4423 - val_accuracy: 0.4000 - val_loss: 0.8565\n",
      "Epoch 74/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8403 - loss: 0.4385 - val_accuracy: 0.4500 - val_loss: 0.7816\n",
      "Epoch 75/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8481 - loss: 0.4219 - val_accuracy: 0.4500 - val_loss: 0.7671\n",
      "Epoch 76/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8298 - loss: 0.4352 - val_accuracy: 0.4500 - val_loss: 0.7525\n",
      "Epoch 77/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8181 - loss: 0.4269 - val_accuracy: 0.4500 - val_loss: 0.8214\n",
      "Epoch 78/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8312 - loss: 0.4516 - val_accuracy: 0.3000 - val_loss: 0.9505\n",
      "Epoch 79/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7932 - loss: 0.4370 - val_accuracy: 0.3000 - val_loss: 0.9862\n",
      "Epoch 80/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7944 - loss: 0.3973 - val_accuracy: 0.3000 - val_loss: 0.9558\n",
      "Epoch 81/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8141 - loss: 0.4322 - val_accuracy: 0.4500 - val_loss: 0.7919\n",
      "Epoch 82/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8481 - loss: 0.3995 - val_accuracy: 0.5500 - val_loss: 0.7196\n",
      "Epoch 83/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8324 - loss: 0.4220 - val_accuracy: 0.4500 - val_loss: 0.7751\n",
      "Epoch 84/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8429 - loss: 0.4338 - val_accuracy: 0.4000 - val_loss: 0.8672\n",
      "Epoch 85/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.4286 - val_accuracy: 0.3500 - val_loss: 0.9472\n",
      "Epoch 86/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8324 - loss: 0.4092 - val_accuracy: 0.3000 - val_loss: 0.9986\n",
      "Epoch 87/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7880 - loss: 0.4270 - val_accuracy: 0.3500 - val_loss: 0.9123\n",
      "Epoch 88/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8195 - loss: 0.4225 - val_accuracy: 0.5000 - val_loss: 0.7526\n",
      "Epoch 89/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8468 - loss: 0.4288 - val_accuracy: 0.6000 - val_loss: 0.6859\n",
      "Epoch 90/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8507 - loss: 0.4070 - val_accuracy: 0.4500 - val_loss: 0.7638\n",
      "Epoch 91/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8195 - loss: 0.4216 - val_accuracy: 0.3000 - val_loss: 0.9508\n",
      "Epoch 92/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8259 - loss: 0.3988 - val_accuracy: 0.2500 - val_loss: 0.9815\n",
      "Epoch 93/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8417 - loss: 0.4234 - val_accuracy: 0.4500 - val_loss: 0.7926\n",
      "Epoch 94/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8651 - loss: 0.3804 - val_accuracy: 0.4500 - val_loss: 0.7778\n",
      "Epoch 95/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8756 - loss: 0.3812 - val_accuracy: 0.4000 - val_loss: 0.8429\n",
      "Epoch 96/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8417 - loss: 0.4062 - val_accuracy: 0.5000 - val_loss: 0.7743\n",
      "Epoch 97/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8639 - loss: 0.3931 - val_accuracy: 0.5000 - val_loss: 0.7587\n",
      "Epoch 98/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8756 - loss: 0.3810 - val_accuracy: 0.5000 - val_loss: 0.7346\n",
      "Epoch 99/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8561 - loss: 0.3824 - val_accuracy: 0.5000 - val_loss: 0.7450\n",
      "Epoch 100/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8639 - loss: 0.3934 - val_accuracy: 0.5500 - val_loss: 0.7440\n",
      "Epoch 101/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8951 - loss: 0.3709 - val_accuracy: 0.4500 - val_loss: 0.7707\n",
      "Epoch 102/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8444 - loss: 0.3937 - val_accuracy: 0.4500 - val_loss: 0.7685\n",
      "Epoch 103/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8756 - loss: 0.3722 - val_accuracy: 0.5000 - val_loss: 0.7546\n",
      "Epoch 104/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.3681 - val_accuracy: 0.5000 - val_loss: 0.7785\n",
      "Epoch 105/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8678 - loss: 0.3746 - val_accuracy: 0.3500 - val_loss: 0.8228\n",
      "Epoch 106/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8561 - loss: 0.3964 - val_accuracy: 0.5000 - val_loss: 0.7450\n",
      "Epoch 107/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8651 - loss: 0.3644 - val_accuracy: 0.6000 - val_loss: 0.7085\n",
      "Epoch 108/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8717 - loss: 0.3679 - val_accuracy: 0.6500 - val_loss: 0.6258\n",
      "Epoch 109/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8744 - loss: 0.3647 - val_accuracy: 0.6500 - val_loss: 0.6421\n",
      "Epoch 110/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8600 - loss: 0.3736 - val_accuracy: 0.6000 - val_loss: 0.7284\n",
      "Epoch 111/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8834 - loss: 0.3320 - val_accuracy: 0.5500 - val_loss: 0.7461\n",
      "Epoch 112/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8861 - loss: 0.3496 - val_accuracy: 0.6500 - val_loss: 0.6349\n",
      "Epoch 113/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8483 - loss: 0.3713 - val_accuracy: 0.7500 - val_loss: 0.5549\n",
      "Epoch 114/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9017 - loss: 0.3424 - val_accuracy: 0.6500 - val_loss: 0.6337\n",
      "Epoch 115/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8678 - loss: 0.3349 - val_accuracy: 0.6500 - val_loss: 0.6348\n",
      "Epoch 116/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8600 - loss: 0.3502 - val_accuracy: 0.6000 - val_loss: 0.6942\n",
      "Epoch 117/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8600 - loss: 0.3562 - val_accuracy: 0.6000 - val_loss: 0.7038\n",
      "Epoch 118/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8600 - loss: 0.3557 - val_accuracy: 0.6000 - val_loss: 0.7120\n",
      "Epoch 119/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8834 - loss: 0.3213 - val_accuracy: 0.6000 - val_loss: 0.7144\n",
      "Epoch 120/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8756 - loss: 0.3292 - val_accuracy: 0.6500 - val_loss: 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define a simple Sequential model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(34,)),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_df, y_df, epochs=120, validation_split=0.2)  # Adjust epochs as needed\n",
    "\n",
    "# Save the model in a format suitable for TensorFlow Lite\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\2001l\\AppData\\Local\\Temp\\ipykernel_25692\\2340584429.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  model = tf.keras.models.load_model('D:\\pose_detection\\pose-detection\\ModelTraining\\model.h5')\n",
      "c:\\Users\\2001l\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\2001l\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('D:\\pose_detection\\pose-detection\\ModelTraining\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_from_squating_images(input_dir,X,Y):\n",
    "    for file in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(img_path) and file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img = Image.open(img_path)\n",
    "            img = tf.image.resize_with_pad(np.expand_dims(img,axis=0), 192, 192)\n",
    "            input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "            # Setup input and output\n",
    "            input_details = interpreter.get_input_details()\n",
    "            output_details = interpreter.get_output_details()\n",
    "\n",
    "            #make predictions\n",
    "            interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "            interpreter.invoke()\n",
    "            keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "            landmarks = keypoints_with_scores\n",
    "\n",
    "            X.append(landmarks)\n",
    "            Y.append(1)\n",
    "    return X,Y\n",
    "\n",
    "def landmarks_from_standing_images(input_dir,X,Y):\n",
    "    for file in os.listdir(input_dir):\n",
    "        img_path = os.path.join(input_dir, file)\n",
    "        \n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(img_path) and file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img = Image.open(img_path)\n",
    "            img = tf.image.resize_with_pad(np.expand_dims(img,axis=0), 192, 192)\n",
    "            input_image = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "            # Setup input and output\n",
    "            input_details = interpreter.get_input_details()\n",
    "            output_details = interpreter.get_output_details()\n",
    "\n",
    "            #make predictions\n",
    "            interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "            interpreter.invoke()\n",
    "            keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "            landmarks = keypoints_with_scores\n",
    "\n",
    "            X.append(landmarks)\n",
    "            Y.append(1)\n",
    "    return X,Y\n",
    "\n",
    "def image_prediction(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img,axis=0), 192, 192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    #make predictions\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    landmarks = keypoints_with_scores\n",
    "    return landmarks[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X,test_Y = landmarks_from_squating_images('test images/sit',[],[])\n",
    "test_X,test_Y = landmarks_from_standing_images('test images/stand',test_X,test_Y)\n",
    "test2_X,test2_Y = landmarks_from_squating_images('test_2',[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1_x       2_x       3_x       4_x       5_x       6_x       7_x  \\\n",
      "0  0.274916  0.262647  0.262242  0.273592  0.273156  0.345524  0.337816   \n",
      "1  0.348626  0.327288  0.325649  0.302239  0.299777  0.357534  0.350932   \n",
      "2  0.235834  0.219170  0.222803  0.235220  0.240305  0.332633  0.314390   \n",
      "3  0.303387  0.288880  0.289168  0.298605  0.295454  0.376998  0.367324   \n",
      "4  0.322320  0.316928  0.312886  0.335187  0.324300  0.397101  0.395000   \n",
      "5  0.222969  0.203214  0.204597  0.211870  0.211155  0.319412  0.305096   \n",
      "6  0.256094  0.244279  0.239573  0.255445  0.251219  0.318392  0.311085   \n",
      "7  0.489945  0.480857  0.482772  0.481763  0.484357  0.529064  0.526707   \n",
      "8  0.182101  0.164650  0.166662  0.175416  0.182256  0.264219  0.269080   \n",
      "9  0.286915  0.271091  0.273656  0.281494  0.282808  0.354996  0.347772   \n",
      "\n",
      "        8_x       9_x      10_x  ...       8_y       9_y      10_y      11_y  \\\n",
      "0  0.451241  0.367750  0.364550  ...  0.468119  0.732583  0.554164  0.744104   \n",
      "1  0.522682  0.520689  0.667113  ...  0.426526  0.522371  0.413822  0.517663   \n",
      "2  0.445779  0.440929  0.417104  ...  0.658704  0.631611  0.715445  0.685782   \n",
      "3  0.447149  0.428515  0.371298  ...  0.363423  0.365263  0.348635  0.348966   \n",
      "4  0.468269  0.467469  0.414952  ...  0.438382  0.341944  0.395720  0.371395   \n",
      "5  0.480113  0.460280  0.326881  ...  0.476177  0.303312  0.383332  0.338014   \n",
      "6  0.379112  0.347369  0.374208  ...  0.489391  0.357254  0.467842  0.282159   \n",
      "7  0.593644  0.533208  0.616790  ...  0.675187  0.519774  0.663546  0.467985   \n",
      "8  0.411407  0.409796  0.331447  ...  0.384525  0.651806  0.467666  0.723884   \n",
      "9  0.441634  0.430651  0.378107  ...  0.360415  0.369306  0.290871  0.293956   \n",
      "\n",
      "       12_y      13_y      14_y      15_y      16_y      17_y  \n",
      "0  0.484691  0.563895  0.604343  0.795072  0.495011  0.719232  \n",
      "1  0.316185  0.359823  0.430940  0.575638  0.374869  0.503239  \n",
      "2  0.471190  0.401492  0.582795  0.544102  0.524180  0.441760  \n",
      "3  0.693750  0.666494  0.501843  0.501646  0.587913  0.574673  \n",
      "4  0.548274  0.483729  0.464450  0.365562  0.531767  0.415800  \n",
      "5  0.647691  0.510187  0.537102  0.322090  0.624519  0.421256  \n",
      "6  0.638951  0.545030  0.548590  0.413356  0.611914  0.465565  \n",
      "7  0.705268  0.651441  0.610966  0.567603  0.655012  0.619076  \n",
      "8  0.437873  0.547540  0.422510  0.792924  0.382129  0.709752  \n",
      "9  0.558377  0.532086  0.387067  0.389252  0.508876  0.483931  \n",
      "\n",
      "[10 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2001l\\AppData\\Local\\Temp\\ipykernel_25692\\341586299.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_test = pd.concat([df_test, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "test_columns = [cols for cols in columns if cols != 'Y']\n",
    "\n",
    "df_test = pd.DataFrame(columns=test_columns)\n",
    "\n",
    "for entry in test2_X:\n",
    "    new_row = {col: None for col in test_columns}\n",
    "    x = 0\n",
    "    for x in range(1,18):\n",
    "        xName = str(x) + '_x'\n",
    "        yName = str(x) + '_y'\n",
    "        new_row[xName] = entry[0][0][x-1][0]\n",
    "        new_row[yName] = entry[0][0][x-1][1]\n",
    "        x = x+1\n",
    "    df_test = pd.concat([df_test, pd.DataFrame([new_row])], ignore_index=True)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29762462],\n",
       "       [0.4569204 ],\n",
       "       [0.31433117],\n",
       "       [0.61837685],\n",
       "       [0.71628904],\n",
       "       [0.50420916],\n",
       "       [0.38703665],\n",
       "       [0.8315349 ],\n",
       "       [0.32332534],\n",
       "       [0.63112974]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
